"""Anthropic Messages API â†’ ChatGPT Responses API í˜•ì‹ ë³€í™˜"""
import json
import uuid
import os
from models import map_model

# ì‹¤ì œ ëª¨ë¸ ì •ë³´ë¥¼ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— í‘œì‹œí• ì§€ ì—¬ë¶€
REVEAL_ACTUAL_MODEL = os.getenv("REVEAL_ACTUAL_MODEL", "false").lower() == "true"


def anthropic_to_responses(body: dict) -> dict:
    """Anthropic Messages API ìš”ì²­ â†’ ChatGPT Responses API ìš”ì²­ ë³€í™˜"""
    input_items = []

    # ì‹¤ì œ ì‚¬ìš©ë˜ëŠ” ëª¨ë¸
    actual_model = map_model(body.get("model", ""))

    # system ë©”ì‹œì§€ êµ¬ì„±
    system_content = ""
    system = body.get("system")
    if system:
        if isinstance(system, list):
            system_content = " ".join(
                b.get("text", "") for b in system if b.get("type") == "text"
            )
        else:
            system_content = system

    # ë„êµ¬ê°€ ìˆì„ ë•Œ ë„êµ¬ ì‚¬ìš© ì§€ì‹œë¥¼ ë§¨ ì•ì— ì¶”ê°€ (ê°€ì¥ ë¨¼ì € ë³´ë„ë¡)
    if body.get("tools"):
        tool_instructions = (
            "=== CRITICAL TOOL USAGE PROTOCOL (READ THIS FIRST) ===\n"
            "You have tools available. When the user asks you to perform ANY action:\n"
            "1. FIRST call the appropriate tool immediately\n"
            "2. THEN provide your response after seeing the tool's result\n"
            "\n"
            "DO NOT just say \"I will read the file\" - actually call the Read tool NOW.\n"
            "DO NOT explain what you would do - DO IT by calling tools.\n"
            "\n"
            "Available tools and when to use them:\n"
            "- Read: When asked to read, view, check, or examine files\n"
            "- Glob/Grep: When asked to find, search, or locate files or code\n"
            "- Bash: When asked to run commands, execute scripts, or check system state\n"
            "- Edit: When asked to modify, change, or update existing files\n"
            "- Write: When asked to create new files or save content\n"
            "\n"
            "Example correct behavior:\n"
            "User: \"read the README file\"\n"
            "You: [IMMEDIATELY call Read tool with path]\n"
            "\n"
            "Example WRONG behavior (DO NOT do this):\n"
            "User: \"read the README file\"\n"
            "You: \"I'll read the README file for you...\" [WITHOUT calling tool] âŒ\n"
            "\n"
            "Remember: Actions speak louder than words. Use tools, don't just talk about using them.\n"
            "=== END CRITICAL PROTOCOL ===\n\n"
        )
        system_content = tool_instructions + (system_content or "")

    # ì‹¤ì œ ëª¨ë¸ ì •ë³´ë¥¼ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€ (ë„êµ¬ ì§€ì‹œ ë‹¤ìŒì—)
    if REVEAL_ACTUAL_MODEL:
        model_identity = (
            f"You are an AI assistant powered by OpenAI's {actual_model} model. "
            f"When asked about your model, identify yourself as {actual_model}, not Claude.\n\n"
        )
        system_content = model_identity + system_content if system_content else model_identity

    # ë©”ì‹œì§€ ë³€í™˜ (systemì€ inputì— ë„£ì§€ ì•Šê³  instructionsë¡œ ì‚¬ìš©)
    for msg in body.get("messages", []):
        items = _convert_message(msg)
        input_items.extend(items)

    result = {
        "model": map_model(body.get("model", "")),
        "input": input_items,
        "stream": body.get("stream", False),
        "store": False,
    }

    # Codex APIëŠ” instructions í•„ìˆ˜ (ì¼ë°˜ Responses APIì™€ ë‹¤ë¦„)
    result["instructions"] = system_content or "You are a helpful assistant."

    # tools ë³€í™˜
    tools = body.get("tools")
    if tools:
        result["tools"] = [_convert_tool(t) for t in tools]
        result["tool_choice"] = "auto"

        # ë„êµ¬ ë³€í™˜ ë¡œê¹…
        tool_names = [t.get("name", "unknown") for t in tools]
        print(f"[converter] ğŸ”§ Converting {len(tools)} tools: {', '.join(tool_names)}")
        print(f"[converter] ğŸ”§ tool_choice set to: auto")
        print(f"[converter] ğŸ”§ instructions required by Codex API (not in input)")

    # ì „ì²´ ìš”ì²­ body ë¡œê¹… (ë””ë²„ê¹…ìš©)
    print("\n[converter] ğŸ“‹ FULL REQUEST BODY:")
    print(f"[converter]   model: {result['model']}")
    print(f"[converter]   stream: {result['stream']}")
    print(f"[converter]   instructions length: {len(result.get('instructions', ''))} chars")
    if result.get("instructions"):
        # instructions ì•ë’¤ 200ìë§Œ í‘œì‹œ
        inst = result["instructions"]
        if len(inst) > 400:
            print(f"[converter]   instructions preview: {inst[:200]}...{inst[-200:]}")
        else:
            print(f"[converter]   instructions: {inst}")
    print(f"[converter]   input items: {len(result['input'])} items")
    for i, item in enumerate(result['input']):
        item_type = item.get('type', 'unknown')
        print(f"[converter]     [{i}] type: {item_type}, role: {item.get('role', 'N/A')}")
        if item_type == "message":
            content = item.get('content', [])
            for c in content:
                c_type = c.get('type', 'unknown')
                if c_type in ['input_text', 'output_text']:
                    text = c.get('text', '')
                    preview = text[:100] if len(text) > 100 else text
                    print(f"[converter]         {c_type}: {preview}...")
    if result.get("tools"):
        print(f"[converter]   tools: {len(result['tools'])} tools defined")
        print(f"[converter]   tool_choice: {result.get('tool_choice', 'N/A')}")
    print("[converter] ğŸ“‹ END REQUEST BODY\n")

    return result


def _convert_message(msg: dict) -> list[dict]:
    """ë‹¨ì¼ ë©”ì‹œì§€ â†’ Responses API input items"""
    role = msg.get("role")
    content = msg.get("content")
    # assistant â†’ output_text, user â†’ input_text
    text_type = "output_text" if role == "assistant" else "input_text"

    if isinstance(content, str):
        return [{
            "type": "message",
            "role": role,
            "content": [{"type": text_type, "text": content}],
        }]

    if not isinstance(content, list):
        return [{
            "type": "message",
            "role": role,
            "content": [{"type": text_type, "text": str(content)}],
        }]

    items = []
    content_parts = []

    for block in content:
        btype = block.get("type")

        if btype == "text":
            content_parts.append({"type": text_type, "text": block.get("text", "")})

        elif btype == "tool_use":
            # ì–´ì‹œìŠ¤í„´íŠ¸ì˜ tool_use â†’ function_call item
            items.append({
                "type": "function_call",
                "id": block.get("id", f"call_{uuid.uuid4().hex[:24]}"),
                "call_id": block.get("id", f"call_{uuid.uuid4().hex[:24]}"),
                "name": block.get("name", ""),
                "arguments": json.dumps(block.get("input", {})),
            })

        elif btype == "tool_result":
            # tool_result â†’ function_call_output item
            tool_content = block.get("content", "")
            if isinstance(tool_content, list):
                tool_content = " ".join(
                    b.get("text", "") for b in tool_content if b.get("type") == "text"
                )
            # call_idê°€ ë¹„ì–´ìˆìœ¼ë©´ ìë™ ìƒì„±
            call_id = block.get("tool_use_id", "") or f"call_{uuid.uuid4().hex[:24]}"
            items.append({
                "type": "function_call_output",
                "id": call_id,  # id í•„ë“œ ì¶”ê°€ (Responses API ìš”êµ¬ì‚¬í•­)
                "call_id": call_id,
                "output": str(tool_content),
            })

        elif btype == "image":
            source = block.get("source", {})
            if source.get("type") == "base64":
                data_uri = (
                    f"data:{source.get('media_type', 'image/png')};"
                    f"base64,{source.get('data', '')}"
                )
                content_parts.append({
                    "type": "input_image",
                    "image_url": data_uri,
                })

        elif btype == "thinking":
            pass  # thinking ë¸”ë¡ ë¬´ì‹œ

    # content_partsê°€ ìˆìœ¼ë©´ message item ì¶”ê°€
    if content_parts:
        items.insert(0, {
            "type": "message",
            "role": role,
            "content": content_parts,
        })

    return items


def _convert_tool(tool: dict) -> dict:
    """Anthropic tool â†’ Responses API function tool"""
    converted = {
        "type": "function",
        "name": tool.get("name", ""),
        "description": tool.get("description", ""),
        "parameters": tool.get("input_schema", {"type": "object"}),
    }

    # ë„êµ¬ë³„ ìƒì„¸ ë¡œê¹… (ì²« 3ê°œë§Œ)
    name = converted["name"]
    if name:
        param_count = len(converted["parameters"].get("properties", {}))
        print(f"[converter]    â€¢ {name}: {param_count} parameters")

    return converted


def responses_to_anthropic(resp_data: dict, model: str) -> dict:
    """ChatGPT Responses API ì‘ë‹µ â†’ Anthropic ì‘ë‹µ ë³€í™˜ (non-streaming)"""
    output = resp_data.get("output", [])
    content = []

    for item in output:
        item_type = item.get("type")
        if item_type == "message":
            for c in item.get("content", []):
                if c.get("type") == "output_text":
                    content.append({"type": "text", "text": c.get("text", "")})
        elif item_type == "function_call":
            try:
                args = json.loads(item.get("arguments", "{}"))
            except json.JSONDecodeError:
                args = {}
            content.append({
                "type": "tool_use",
                "id": item.get("call_id", f"toolu_{uuid.uuid4().hex[:24]}"),
                "name": item.get("name", ""),
                "input": args,
            })

    status = resp_data.get("status", "completed")
    stop_reason = "tool_use" if any(
        i.get("type") == "function_call" for i in output
    ) else "end_turn"

    usage = resp_data.get("usage", {})

    return {
        "id": resp_data.get("id", f"msg_{uuid.uuid4().hex[:24]}"),
        "type": "message",
        "role": "assistant",
        "content": content,
        "model": model,
        "stop_reason": stop_reason,
        "stop_sequence": None,
        "usage": {
            "input_tokens": usage.get("input_tokens", 0),
            "output_tokens": usage.get("output_tokens", 0),
        },
    }
